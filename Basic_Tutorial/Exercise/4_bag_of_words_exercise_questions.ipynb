{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYoVrnewenmh"
   },
   "source": [
    "### Bag of words: Exercises\n",
    "\n",
    "\n",
    "- In this Exercise, you are going to classify whether a given movie review is **positive or negative**.\n",
    "- you are going to use Bag of words for pre-processing the text and apply different classification algorithms.\n",
    "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JW6MPIjib_4G"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDATDCL8NMML"
   },
   "source": [
    "### **About Data: IMDB Dataset**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - review\n",
    "        - sentiment\n",
    "- Reviews are the statements given by users after watching the movie.\n",
    "- sentiment feature tells whether the given review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "beL29JwEb_7O",
    "outputId": "cf0a9e1e-b80b-4447-d759-0828baba2620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2)\n",
      "                                              review sentiment\n",
      "0  I first saw Jake Gyllenhaal in Jarhead (2005) ...  positive\n",
      "1  I enjoyed the movie and the story immensely! I...  positive\n",
      "2  I had a hard time sitting through this. Every ...  negative\n",
      "3  It's hard to imagine that anyone could find th...  negative\n",
      "4  This is one military drama I like a lot! Tom B...  positive\n"
     ]
    }
   ],
   "source": [
    "#1. read the data provided in the same directory with name 'movies_sentiment_data.csv' and store it in df variable\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\owaisaaa\\\\Desktop\\\\Tutorials\\\\NLP\\\\NLP_Tutorial_Basics\\\\movies_sentiment_data.csv\")\n",
    "\n",
    "#2. print the shape of the data\n",
    "print(df.shape)\n",
    "\n",
    "#3. print top 5 datapoints\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  Category\n",
      "0  I first saw Jake Gyllenhaal in Jarhead (2005) ...  positive         1\n",
      "1  I enjoyed the movie and the story immensely! I...  positive         1\n",
      "2  I had a hard time sitting through this. Every ...  negative         0\n",
      "3  It's hard to imagine that anyone could find th...  negative         0\n",
      "4  This is one military drama I like a lot! Tom B...  positive         1\n"
     ]
    }
   ],
   "source": [
    "#creating a new column \"Category\" which represent 1 if the sentiment is positive or 0 if it is negative\n",
    "df['Category'] = df['sentiment'].apply(lambda x:1 if x == 'positive' else 0 )\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSwPM7mub_9S",
    "outputId": "2b68719c-b7f4-48b8-a41e-3f95cca9f2f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "1    9500\n",
       "0    9500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of 'Category' and see whether the Target labels are balanced or not.\n",
    "\n",
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IB97QiFCcAAe"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20%\n",
    "# from sklearn.model_selection import train_test_split => already done at the top\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.Category, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mtr4mSLEMWiU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3654    This movie could be a bit boring for some peop...\n",
       "6452    this movie is the worst EVER!!! sorry but this...\n",
       "9078    Imagine a film the complete opposite of Lawren...\n",
       "4685    Okay they tell you it's real. They don't list ...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3654    1\n",
       "6452    0\n",
       "9078    0\n",
       "4685    0\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-pUGPqwMrDQ"
   },
   "source": [
    "**Exercise-1**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative.\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "\n",
    "- use **Random Forest** as the classifier with estimators as 50 and criterion as entropy.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbldZv03MWkB",
    "outputId": "cf70d361-da12-46a9-8d59-73cdba9bad91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1941\n",
      "           1       0.83      0.84      0.83      1859\n",
      "\n",
      "    accuracy                           0.84      3800\n",
      "   macro avg       0.84      0.84      0.84      3800\n",
      "weighted avg       0.84      0.84      0.84      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer => already done at top\n",
    "# from sklearn.ensemble import RandomForestClassifier   => already done at top\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),                                                      #initializing the vectorizer\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, criterion='entropy'))                    #using the RandomForest classifier\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMVvGzqXSFYr"
   },
   "source": [
    "**Exercise-2**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use **KNN** as the classifier with n_neighbors of 10 and metric as 'euclidean'.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYkY77S6MWng",
    "outputId": "53275bdc-4629-464c-d26f-00075b080174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1941\n",
      "           1       0.63      0.66      0.64      1859\n",
      "\n",
      "    accuracy                           0.64      3800\n",
      "   macro avg       0.64      0.64      0.64      3800\n",
      "weighted avg       0.64      0.64      0.64      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports already done at the top\n",
    "\n",
    "clf_knn = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=10, metric='euclidean'))               #using the KNN classifier with 10 neighbors\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-3**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use **Multinomial Naive Bayes** as the classifier.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      1941\n",
      "           1       0.85      0.83      0.84      1859\n",
      "\n",
      "    accuracy                           0.85      3800\n",
      "   macro avg       0.85      0.85      0.85      3800\n",
      "weighted avg       0.85      0.85      0.85      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports already done at the top\n",
    "\n",
    "clf_nb = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())             #using the Multinomial Naive Bayes classifier\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf_nb.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf_nb.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you write some observations of why model like KNN fails to produce good results unlike RandomForest and MultinomialNB?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As Machine learning algorithms does not work on Text data directly, we need to convert them into numeric vector and feed that into models while training.\n",
    "- In this process, we convert text into a very high dimensional numeric vector using the technique of Bag of words.\n",
    "- Model like K-Nearest Neighbours(KNN) doesn't work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of model.\n",
    "- The easy calculation of probabilities for the words in corpus(Bag of words) and storing them in contigency table is the major reason for the Multinomial NaiveBayes to be a text classification friendly algorithm.\n",
    "- As Random Forest uses Bootstrapping(Row and column Sampling) with many decision tree and overcomes the high variance and overfitting of high dimensional data and also uses feature importance of words for better classifing the categories.\n",
    "- Machine Learning is like trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which give good results and satisfy the requirements like latency, interpretability etc.\n",
    "\n",
    "#### Refer these resources to get good idea:\n",
    "\n",
    "https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/<br>\n",
    "https://analyticsindiamag.com/naive-bayes-why-is-it-favoured-for-text-related-tasks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BOW_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
